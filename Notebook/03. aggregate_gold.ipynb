{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3084e61f-b95d-490c-a3ec-48eeaa4c8976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Objetivo do Notebook é gerar dados da camada Gold, como:\n",
    "\n",
    "Receita total por mês\n",
    "\n",
    "Número de pedidos por canal\n",
    "\n",
    "Ticket médio por loja\n",
    "\n",
    "Distância média de entrega\n",
    "\n",
    "Total de pedidos por cidade\n",
    "\n",
    "Entregas por motorista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85349933-75f3-47aa-9c32-7cca6201e9da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01471c02-ef9f-459f-ae15-37d1d7aaf58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, concat_ws\n",
    "\n",
    "# Caminhos das camadas Bronze e Silver\n",
    "bronze_base = \"/Volumes/workspace/default/ifood-files/bronze/\"\n",
    "silver_base = \"/Volumes/workspace/default/ifood-files/silver/delivery_center_enriched\"\n",
    "\n",
    "# Leitura das tabelas Bronze\n",
    "channels   = spark.read.format(\"delta\").load(f\"{bronze_base}channels\")\n",
    "deliveries = spark.read.format(\"delta\").load(f\"{bronze_base}deliveries\")\n",
    "drivers    = spark.read.format(\"delta\").load(f\"{bronze_base}drivers\")\n",
    "hubs       = spark.read.format(\"delta\").load(f\"{bronze_base}hubs\")\n",
    "orders     = spark.read.format(\"delta\").load(f\"{bronze_base}orders\")\n",
    "payments   = spark.read.format(\"delta\").load(f\"{bronze_base}payments\")\n",
    "stores     = spark.read.format(\"delta\").load(f\"{bronze_base}stores\")\n",
    "\n",
    "# Criar timestamp do pedido\n",
    "orders = orders.withColumn(\n",
    "    \"order_purchase_timestamp\",\n",
    "    to_timestamp(concat_ws(\"-\", \"order_created_year\", \"order_created_month\", \"order_created_day\"))\n",
    ")\n",
    "\n",
    "# JOINs com aliases\n",
    "df = orders.alias(\"o\") \\\n",
    "    .join(payments.alias(\"p\"), col(\"o.order_id\") == col(\"p.payment_order_id\"), \"left\") \\\n",
    "    .join(stores.alias(\"s\"), col(\"o.store_id\") == col(\"s.store_id\"), \"left\") \\\n",
    "    .join(channels.alias(\"c\"), col(\"o.channel_id\") == col(\"c.channel_id\"), \"left\") \\\n",
    "    .join(deliveries.alias(\"d\"), col(\"o.order_id\") == col(\"d.delivery_order_id\"), \"left\") \\\n",
    "    .join(drivers.alias(\"dr\"), col(\"d.driver_id\") == col(\"dr.driver_id\"), \"left\") \\\n",
    "    .join(hubs.alias(\"h\"), col(\"s.hub_id\") == col(\"h.hub_id\"), \"left\")\n",
    "\n",
    "# Seleção das colunas relevantes\n",
    "df = df.select(\n",
    "    col(\"o.order_id\").alias(\"order_id\"),\n",
    "    col(\"o.order_status\").alias(\"order_status\"),\n",
    "    col(\"order_purchase_timestamp\"),\n",
    "    col(\"p.payment_method\").alias(\"payment_method\"),\n",
    "    col(\"p.payment_amount\").alias(\"payment_amount\"),\n",
    "    col(\"s.store_id\").alias(\"store_id\"),\n",
    "    col(\"s.store_name\").alias(\"store_name\"),\n",
    "    col(\"s.hub_id\").alias(\"hub_id\"),\n",
    "    col(\"c.channel_id\").alias(\"channel_id\"),\n",
    "    col(\"c.channel_type\").alias(\"channel_type\"),\n",
    "    col(\"d.delivery_id\").alias(\"delivery_id\"),\n",
    "    col(\"d.delivery_distance_meters\").alias(\"delivery_distance_meters\"),\n",
    "    col(\"dr.driver_id\").alias(\"driver_id\"),\n",
    "    col(\"dr.driver_type\").alias(\"driver_type\"),  # ← substituto de driver_name\n",
    "    col(\"h.hub_city\").alias(\"hub_city\"),\n",
    "    col(\"h.hub_state\").alias(\"hub_state\")\n",
    ")\n",
    "\n",
    "# Remover duplicatas\n",
    "df = df.dropDuplicates([\"order_id\"])\n",
    "\n",
    "# Escrita na camada Silver\n",
    "df.write \\\n",
    "  .format(\"delta\") \\\n",
    "  .option(\"mergeSchema\", \"true\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save(silver_base)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03. aggregate_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
