{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5afad17a-ba85-4fb2-be0f-a4ea32f360ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders = spark.read.format(\"delta\").load(\"/Volumes/workspace/default/ifood-files/bronze/orders\")\n",
    "orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6c5182e-29aa-482a-b826-01fbe1cd838f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deliveries = spark.read.format(\"delta\").load(\"/Volumes/workspace/default/ifood-files/bronze/deliveries\")\n",
    "deliveries.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "329df38d-4e38-410c-97c1-1d4a4e6ce035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(deliveries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bace10a6-d833-44c9-9885-354a5a495f64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, concat_ws\n",
    "\n",
    "# Caminhos das camadas Bronze e Silver\n",
    "bronze_base = \"/Volumes/workspace/default/ifood-files/bronze/\"\n",
    "silver_base = \"/Volumes/workspace/default/ifood-files/silver/delivery_center_enriched\"\n",
    "\n",
    "# Leitura das tabelas Bronze\n",
    "channels   = spark.read.format(\"delta\").load(f\"{bronze_base}channels\")\n",
    "deliveries = spark.read.format(\"delta\").load(f\"{bronze_base}deliveries\")\n",
    "drivers    = spark.read.format(\"delta\").load(f\"{bronze_base}drivers\")\n",
    "hubs       = spark.read.format(\"delta\").load(f\"{bronze_base}hubs\")\n",
    "orders     = spark.read.format(\"delta\").load(f\"{bronze_base}orders\")\n",
    "payments   = spark.read.format(\"delta\").load(f\"{bronze_base}payments\")\n",
    "stores     = spark.read.format(\"delta\").load(f\"{bronze_base}stores\")\n",
    "\n",
    "# Reconstruindo coluna de timestamp do pedido\n",
    "orders = orders.withColumn(\n",
    "    \"order_purchase_timestamp\",\n",
    "    to_timestamp(concat_ws(\"-\", \"order_created_year\", \"order_created_month\", \"order_created_day\"))\n",
    ")\n",
    "\n",
    "# Realizando os joins com aliases\n",
    "df = orders.alias(\"o\") \\\n",
    "    .join(payments.alias(\"p\"), col(\"o.order_id\") == col(\"p.payment_order_id\"), \"left\") \\\n",
    "    .join(stores.alias(\"s\"), col(\"o.store_id\") == col(\"s.store_id\"), \"left\") \\\n",
    "    .join(channels.alias(\"c\"), col(\"o.channel_id\") == col(\"c.channel_id\"), \"left\") \\\n",
    "    .join(deliveries.alias(\"d\"), col(\"o.order_id\") == col(\"d.delivery_order_id\"), \"left\") \n",
    "   \n",
    "\n",
    "# Seleção das colunas com alias para nomes limpos (sem prefixos)\n",
    "df = df.select(\n",
    "    col(\"o.order_id\").alias(\"order_id\"),\n",
    "    col(\"o.order_status\").alias(\"order_status\"),\n",
    "    col(\"order_purchase_timestamp\"),\n",
    "    col(\"p.payment_method\").alias(\"payment_method\"),\n",
    "    col(\"p.payment_amount\").alias(\"payment_amount\"),\n",
    "    col(\"s.store_id\").alias(\"store_id\"),\n",
    "    col(\"s.store_name\").alias(\"store_name\"),  # Corrected column name\n",
    "    col(\"s.hub_id\").alias(\"hub_id\"),  # Corrected column name\n",
    "    col(\"c.channel_id\").alias(\"channel_id\"),\n",
    "    col(\"c.channel_type\").alias(\"channel_type\"),\n",
    "    col(\"d.delivery_id\").alias(\"delivery_id\"),\n",
    "    col(\"d.delivery_distance_meters\").alias(\"delivery_distance_meters\")\n",
    ")\n",
    "\n",
    "# Agora sim, deduplicar pelo nome limpo\n",
    "df = df.dropDuplicates([\"order_id\"])\n",
    "\n",
    "# Escrita final na camada Silver\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(silver_base)\n",
    "\n",
    "# Visualizar os dados\n",
    "df_check = spark.read.format(\"delta\").load(silver_base)\n",
    "display(df_check.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c18d6f61-28fe-4cb5-9576-fd0c0ca63f22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, concat_ws\n",
    "\n",
    "# Caminhos das camadas Bronze e Silver\n",
    "bronze_base = \"/Volumes/workspace/default/ifood-files/bronze/\"\n",
    "silver_base = \"/Volumes/workspace/default/ifood-files/silver/delivery_center_enriched\"\n",
    "\n",
    "# Leitura das tabelas Bronze\n",
    "channels   = spark.read.format(\"delta\").load(f\"{bronze_base}channels\")\n",
    "deliveries = spark.read.format(\"delta\").load(f\"{bronze_base}deliveries\")\n",
    "drivers    = spark.read.format(\"delta\").load(f\"{bronze_base}drivers\")\n",
    "hubs       = spark.read.format(\"delta\").load(f\"{bronze_base}hubs\")\n",
    "orders     = spark.read.format(\"delta\").load(f\"{bronze_base}orders\")\n",
    "payments   = spark.read.format(\"delta\").load(f\"{bronze_base}payments\")\n",
    "stores     = spark.read.format(\"delta\").load(f\"{bronze_base}stores\")\n",
    "\n",
    "# Reconstruindo coluna de timestamp do pedido\n",
    "orders = orders.withColumn(\n",
    "    \"order_purchase_timestamp\",\n",
    "    to_timestamp(concat_ws(\"-\", \"order_created_year\", \"order_created_month\", \"order_created_day\"))\n",
    ")\n",
    "\n",
    "# Realizando os joins com aliases\n",
    "df = orders.alias(\"o\") \\\n",
    "    .join(payments.alias(\"p\"), col(\"o.order_id\") == col(\"p.payment_order_id\"), \"left\") \\\n",
    "    .join(stores.alias(\"s\"), col(\"o.store_id\") == col(\"s.store_id\"), \"left\") \\\n",
    "    .join(channels.alias(\"c\"), col(\"o.channel_id\") == col(\"c.channel_id\"), \"left\") \\\n",
    "    .join(deliveries.alias(\"d\"), col(\"o.order_id\") == col(\"d.delivery_order_id\"), \"left\") \\\n",
    "    .join(hubs.alias(\"h\"), col(\"s.hub_id\") == col(\"h.hub_id\"), \"left\") \\\n",
    "    .join(drivers.alias(\"dr\"), col(\"d.driver_id\") == col(\"dr.driver_id\"), \"left\")\n",
    "\n",
    "# Seleção das colunas com alias para nomes limpos (sem prefixos)\n",
    "df = df.select(\n",
    "    col(\"o.order_id\").alias(\"order_id\"),\n",
    "    col(\"o.order_status\").alias(\"order_status\"),\n",
    "    col(\"order_purchase_timestamp\"),\n",
    "    col(\"p.payment_method\").alias(\"payment_method\"),\n",
    "    col(\"p.payment_amount\").alias(\"payment_amount\"),\n",
    "    col(\"s.store_id\").alias(\"store_id\"),\n",
    "    col(\"s.store_name\").alias(\"store_name\"),\n",
    "    col(\"s.hub_id\").alias(\"hub_id\"),\n",
    "    col(\"c.channel_id\").alias(\"channel_id\"),\n",
    "    col(\"c.channel_type\").alias(\"channel_type\"),\n",
    "    col(\"d.delivery_id\").alias(\"delivery_id\"),\n",
    "    col(\"d.delivery_distance_meters\").alias(\"delivery_distance_meters\"),\n",
    "    col(\"h.hub_city\").alias(\"hub_city\"),\n",
    "    col(\"h.hub_state\").alias(\"hub_state\"),\n",
    "    col(\"dr.driver_id\").alias(\"driver_id\"),\n",
    "    col(\"dr.driver_name\").alias(\"driver_name\")\n",
    ")\n",
    "\n",
    "# Remover duplicatas pelo order_id\n",
    "df = df.dropDuplicates([\"order_id\"])\n",
    "\n",
    "# Escrita final na camada Silver\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(silver_base)\n",
    "\n",
    "# Visualizar os dados\n",
    "df_check = spark.read.format(\"delta\").load(silver_base)\n",
    "display(df_check.limit(10))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02. transform_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
